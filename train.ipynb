{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d24f4ea-aacb-4eea-ac12-298607c18227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(data_train, labels_train):\n",
    "    #data_train (.npy file) will be used to train model with test and val sets\n",
    "    #labels_train (.npy file) will be used to test model with labels for test and val sets\n",
    "    \n",
    "    #loading training data\n",
    "    import numpy as np\n",
    "    import gc\n",
    "    data_train = np.load(data_train)\n",
    "    \n",
    "    #reshaping array to unflatten it to a multidimensional array of size (# of images,imagesize,imagesize,3)\n",
    "    total_photos=data_train.shape[1]\n",
    "    img_size = 300\n",
    "    reshaped_train = np.zeros((total_photos,img_size,img_size,3))\n",
    "\n",
    "    for i in range(total_photos):\n",
    "       reshaped_train[i] = np.reshape(data_train[:,0],(1,img_size,img_size,3))\n",
    "       if i == total_photos - 1:\n",
    "            del data_train\n",
    "            gc.collect()\n",
    "       else:\n",
    "          data_train = data_train[:,1:]\n",
    "    reshaped_train = reshaped_train.astype('int16') \n",
    "    \n",
    "    \n",
    "    #resize to a smaller image\n",
    "    import cv2\n",
    "\n",
    "    new_size = 224\n",
    "    resized_train = np.zeros((reshaped_train.shape[0],new_size,new_size,3))\n",
    "\n",
    "    for i in range(total_photos):\n",
    "        resized_train[i] = cv2.resize(reshaped_train[i],dsize = (new_size,new_size),interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    del reshaped_train\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    #split between training and validation for model\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    labels_train = np.load(labels_train)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(resized_train, \n",
    "                                                                    labels_train,\n",
    "                                                                    random_state = 0,\n",
    "                                                                    test_size = 0.2,\n",
    "                                                                    stratify = labels_train)\n",
    "    del resized_train\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    #converting to 32bit float type\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    #tensorflow libraries\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, BatchNormalization , Dropout, Rescaling, GlobalAveragePooling2D\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    #hyperparameters\n",
    "    dropout_rate = 0.8\n",
    "    learning_rate = 1e-4\n",
    "    \n",
    "    #transfer learning model\n",
    "    base_model = tf.keras.applications.MobileNetV2(weights='imagenet',\n",
    "                                            input_shape=(224, 224, 3),\n",
    "                                            include_top=False)                \n",
    "    #all weights are trainable\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    #creating sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #scaling between -1 and 1\n",
    "    model.add(Rescaling(1./127.5, offset=-1))\n",
    "    \n",
    "    #adding transfer learning model\n",
    "    model.add(base_model)\n",
    "    \n",
    "    #GlobalAveragePooling layer\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    #Dropout layer\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    #BatchNormalize layer\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    #Output layer with softmax **change for extra credit\n",
    "    model.add(Dense(10, activation = 'Softmax'))\n",
    "\n",
    "    #compiling model with Nadam\n",
    "    model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate = learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    #callback will stop after val_loss does not go down in 20 epochs\n",
    "    #will save best performing model\n",
    "    callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                                 patience = 20,\n",
    "                                                 restore_best_weights = True)\n",
    "\n",
    "    #training model\n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        epochs=100,\n",
    "                        callbacks = [callbacks],\n",
    "                        validation_data=(x_test, y_test))\n",
    "    \n",
    "    #save model\n",
    "    model.save(\"logo_classification_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7aeda8-d5ad-4e3b-977d-9f3201b6b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model here if needed\n",
    "train(#, #)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
